---
title: "Who’s Afraid of the Big Bad Woke? An Admittedly Slapdash Comment on Clark et al (2024)"
shorttitle: COMMENT ON CLARK ET AL
author:
  - name: Timothy J. Luke
    corresponding: true
    email: timothy.luke@psy.gu.se
    affiliations:
      - name: Department of Psychology, University of Gothenburg
abstract: |
  A friend sent me a copy of Clark et al (2024, 10.1177/17456916241252085)
  saying they thought it was interesting. One of the authors' central
  conclusions is that psychology professors in the US who believe in
  controversial statements (e.g., that racial differences in IQ are driven by
  genetic factors) are more likely to "self-censor" those beliefs. I took one
  look at the article and thought, "That can't be right. It can't be that
  simple." And over the next couple weeks, on and off, I reanalyzed their data.
  This comment is the result of those reanalyses. In short, a straightforward
  positive relationship between belief in controversial ideas and
  self-censorship is not actually supported by their data. The story is more
  complicated and is incompatible with the idea of pervasive and systematic bias
  against "taboo" discussions in psychology.
format: apaquarto-pdf 
documentmode: jou
bibliography: references.bib
---

Recently, @Clark_2024 reported data from a 2021 survey of US psychology professors, in which participants answered questions about controversial ideas in psychology (what Clark et al call "taboos"). They specifically examined ten controversial ideas, such as the idea that racial differences in IQ scores have a nontrivial genetic basis, that sexually coercive behavior has evolutionary benefits, and that diversity sometimes leads to poorer workplace performance. Among many results, Clark et al reported that belief in the truth of these controversial ideas was positively correlated with "self-censorship" -- an unwillingness to voice one's beliefs openly. This consistent correlation is one of their central findings and appears to support their conclusion that "the professional discourse... surrounding taboo topics may be systematically biased toward rejecting taboo conclusions because those who hold taboo empirical beliefs are more likely to remain silent than others" (p.14). 

As someone who spends a lot of time around psychology professors, this conclusion didn't jibe with my personal experience. People around me say all kinds of wild controversial stuff. I found myself skeptical of the authors' broad conclusions about pervasive bias against the expression of controversial ideas. To their credit, Clark et al made their data publicly available on the Open Science Framework. So I looked at the data. It turns out that a straightforward positive relationship between belief in controversial ideas and self-censorship is not actually supported by their data. The story is more complicated and is incompatible with the idea of pervasive and systematic bias against "taboo" discussions.

# Some Conceptual and Methodological Remarks

Before we look at the data, I want to highlight some conceptual and methodological issues, partly to help set up later arguments and partly to get you, dear reader, to start asking questions about why @Clark_2024 is written the way that it is. 

First, Clark et al label one of their key variables “self-censorship.” It’s in the title of the paper. But self-censorship is a behavior – the act (or non-act, I suppose) of not saying something. And the item referred to as “self-censorship” read as follows: “If the topic came up in a professional setting – for example, at a conference – how reluctant would you feel about sharing your beliefs on this topic openly?” Is this self-censorship? Or is this hypothetical reluctance? Contrast this item phrasing with the phrasing of the following interview question from Clark et al's pilot study: “On a 0 to 100 scale, how often do you keep your views on that topic to yourself and avoid sharing them openly with your peers and the public, 0 being ‘I never self-censor’ and 100 being ‘I self-censor all the time’?” This question has other issues (e.g., conflation of peer and public contexts), but it does get more directly at self-censoring behavior, rather than reluctance. Speaking only for myself, there are loads of things I do reluctantly – but I still do them. I am writing this commentary reluctantly, but I am still doing it. I raise this issue not only because I think it has implications for the construct inferences Clark et al draw but also because the notion that this item measures (hypothetical) reluctance to speak, rather than self-censorship specifically, is going to be important later when we get to the data.

Second, in several places, Clark et al refer to the evaluations of the truth of each of the statements as “empirical beliefs.” But the item used to measure beliefs read “How confident are you in the truth or falsity of this statement?” They were not asked to evaluate the empirical evidence for the statement. They were just asked if they believed it. Despite possible indications to the contrary, psychological scientists are people, and people don’t base their beliefs solely (or even necessarily primarily) on empirical evidence. It’s also important to remember that the sample was not selected for their expertise on the science pertaining to these statements. They are not even necessarily equipped to evaluate these statements in relation to the existing science. These issues are also important for interpreting the results. We’re not dealing with cold assessments of the current state of the science. We’re dealing with beliefs – the beliefs of professors, but those are still normal messy human beliefs.

There is another issue related to the belief item worth addressing. The item measuring belief in each of the statements was anchored at 0 and 100 with the labels “100% confident it is false” and “100% confident it is true.” This bipolar anchoring means that the midpoint of 50 (technically 49) represents total uncertainty about the truth of the statement. That is, uncertainty is nonlinear across this response scale. This feature may seem innocuous, but again, it’s going to be important later.

# A Brief Detour into Politics (and Statistics)

As Clark et al point out, over the last several years, many individuals and organizations have been raising the alarm that academia may be under attack by censorious forces [see, e.g., @Haidt_2019]. As scholars studying this development have noted, however, this alarm ringing has not been a purely spontaneous social movement. Rather, many of the organizations that have loudly condemned perceived censorship in the academy have been financially supported and developed by right-wing and libertarian political actors [see, e.g., @Wilson_kamola_2021]. For example, the Foundation for Individual Rights and Expression (FIRE) which Clark et al cite in their introduction, has received at least $13.6 million since the year 2000 from the donor network of the wealthy Koch family. Encouraged by these organizations, the media has disproportionately reported on cases where conservative ideas appear to be under threat in academia [@Franks_2019]. In their analysis of this political apparatus, @Wilson_kamola_2021 illustrate the output of this system with an article in *Inside Higher Ed* describing campus free speech legislation, in which all but one of the quoted and cited sources had traceable funding from a shared network of right-wing political organizations [@BauerWolf_2019]. Being the result of political activity does not, of course, in itself render concerns or discourse illegitimate. Loads of political causes have legitimate concerns. But the conservative political origins of the discourse around the (self-)censorship of controversial scientific ideas can potentially help explain some of the findings of Clark et al. For example, they found that conservatism was positively correlated with belief in the controversial statements, with reluctance to express one's beliefs on the statements, and with fear of all nine potential negative consequences of expressing belief in the controversial statements (e.g., being attacked on social media, student boycotts, threats of physical violence). These correlations make intuitive sense, especially given that all but one of the ten "taboo" statements examined by @Clark_2024 would, if true, be convenient for many conservative political positions. 

Consider that there are around 40,000 people teaching psychology in postsecondary educational institutions in the United States, according to the US Bureau of Labor Statistics, and there are just under 4,000 degree-granting postsecondary educational institutions in the US, according to the National Center for Education Statistics. These numbers provide a context for understanding the frequency of alleged incidents of speech suppression on campuses. If we take the report by FIRE [@German_Stevens_2022] cited by @Clark_2024 at face value^[I encourage interested readers to examine this report more closely. Unfortunately, I don't have the time and resources for a thorough review of it, but even a quick glance at their list of top ten worst incidents of scholars being targeted raised an eyebrow. Even my incidental knowledge of some of the cases made me skeptical of the framing in the report. Take for example the case of Jason Kilborn, whom the report describes as follows: "Kilborn was suspended after a student complaint about an exam question that presented expurgated racial and misogynistic slurs." This description is technically true. In terms of the sequence of events, he was suspended *after* complaints about the test question, but his suspension (with pay, for a few days) didn't occur on the basis of that complaint. He was suspended on the basis that, when a representative of a Black students association asked him why he thought the complaints were not delivered directly to him but had been mediated through a third party, he surmised (supposedly jokingly) that it was because if he'd received the complaints directly he would "become homicidal". In this same meeting, he described the complaining students as "enemies" and expressed a desire to "go after people who 'come at [him]'". For further context, this meeting occurred on January 7, 2021 -- the day after the US Capitol was stormed; political violence weighed heavily on many people's minds. The suspension occurred on the grounds that this behavior was taken as a potential threat, rather than on the grounds that the exam question was objectionable. Perhaps you think this behavior should be protected under principles of academic freedom and free speech or that administrative leave is an overkill remedy. But in any event, an ordinary person reading the synopsis in the FIRE report would, through the ordinary process of pragmatic implicature, assume the exam question complaint and suspension were directly causally related. And the facts do not really bear that out. Elsewhere, FIRE is even more direct. For example, the head of their Faculty Legal Defense Fund said Kilborn had been "crucifie[d]... for using a redacted slur" [@Fire_2022]. This case is actually even more complicated and involves several other allegations of discrimination and harassment (see, e.g., *Kilborn v. Amiridis*, 22 C 475, especially Exhibit A). The case is, in short, messy. But this footnote is already too long, and I don't want to thoroughly litigate this case, let alone all the cases they cite. But I do want to highlight the manner in which at least some of these cases were framed in the report -- that is, in my view, in a manner potentially misleading in its conspicuous incompleteness. There are many ways of framing any given story, so why frame this particular case in this way? It can be useful to consider the kind of narrative that this sort of framing helps to construct.], suggesting that there were 537 cases of attempted speech suppression of scholars at US higher education institutions from 2015 to 2021, of which 107 were in a teaching context and 106 were in a scientific context (with an overlap of 37 cases, for a total of 176 unique cases in seven years), we are dealing with incidents that are infrequent, given the wider context. Press coverage of plane crashes can make people genuinely anxious about flying, but it doesn't mean that air travel is actually unsafe in a pervasive sense. Purely based on the numbers, the vast majority of scholars are going to be spectators in the theater of the politics of academic freedom, rather than major players. My point is not to dismiss anyone's genuine anxiety about getting mobbed on social media or subjected to a petition calling for your firing. Rather, my point is that for almost all of us, those threats are purely hypothetical. The immediate experience of the majority of scholars will, therefore, not be in line with the political narrative we are talking about. In light of this, it should not be surprising if many (if not the majority of) scholars do not feel their academic freedom to be in any peril, while some, especially those exposed to this narrative and the corresponding media coverage, may believe academic freedom is under fire.

Perhaps you have read this section and think it's just political hackery. If so, you and I are probably going to have to agree to disagree. However, for the sake of generating hypotheses, please indulge me. Let's for now take it as a given that there exists a political narrative that the free expression of certain (generally conservative) ideas is under attack in the academy. Let's also assume that this narrative holds sway over some people but not others. Indeed, @Clark_2024 note that "scholars sometimes quarrel about whether academic freedom is at risk" (p.14). And yeah, here I am, quarreling. Assuming these premises, what might we expect to observe in the relationship between belief in these controversial ideas and reluctance to express them? We'd likely see variation, on the individual level, in the relationship between controversial beliefs and reluctance to express those beliefs in professional contexts. That is, some people would show a positive relationship between belief and reluctance (i.e., the people who buy the narrative), and some people wouldn't or would show a much weaker relationship (i.e., people who don't buy the narrative or at least do not fully subscribe to it).

But if the population of psychology professors is a mix of different types of people (e.g., subscribers and non-subscribers to this political narrative), observed data from a sample drawn from that population analyzed at a group level will almost certainly misleadingly conceal what is happening at an individual level. Even though many of us receive a warning at some point in our training about the dangers of applying inferences from the group (nomothetic) level to the individual (idiographic) level, a lot of us just power through and use group-level models to examine phenomena that are almost certainly composed of multiple phenomena occurring at an individual level. I'm not here to get on a high horse about this issue; I've done it myself and will probably do it again. But it remains a huge problem, and if not attended to, a disconnect between nomothetic and idiographic patterns can undermine important conclusions. 

Imagine we asked people to estimate the risk of plane crashes under several different circumstances (e.g., in bad weather, with older planes) and asked them how anxious they would be to fly in each of those conditions. In a typical nomothetic approach, we might calculate correlations between these measures, and we would almost certainly find positive associations in all cases. Very roughly, this approach would address the question, "Does anxiety about plane crashes exist?" With this example, you probably immediately realize that analyzing the data in this way is crude, perhaps to the point of triviality. Experience, intuition, and a tiny bit of reasoning tell us that some people will be anxious because of crash risk, some people might be anxious under all circumstances, and other people simply won't care. The group-level correlations will be fundamentally unable to describe these different kinds of people. In the context of @Clark_2024, a purely nomothetic approach can potentially address the question, "Does a fear about expressing belief in controversial ideas exist?" But it cannot answer the more important question, "Who is afraid of expressing their beliefs about controversial issues?" Let me show you.

# Let's Have Another Look at the Data

## People Are Different

Clark et al analyzed the relationship between belief in each statement and reluctance to express one's beliefs separately for each statement, and they found consistent positive correlations between belief and reluctance.^[Only one of the controversial statements (concerning the existence of racial bias in academia) featured a negative correlation between belief and reluctance. As Clark et al point out, this statement is thematically different than the others, so for the purposes of my analyses, I reverse coded belief for this statement.] These relationships were modeled linearly, as correlations and regressions, and they are visualized in Figure 1 in Clark et al (p.10-11). I encourage you to check out that figure. It's an elegant summary of the results. I have reproduced it in @fig-fig-1 here.

```{r}
#| label: fig-fig-1
#| fig-cap: Reproduction of Figure 1 from Clark et al (2024), Correlations between belief in statements and reluctance.  Regression lines represent linear relationships
#| apa-twocolumn: true
#| out-width: "7in"

knitr::include_graphics("figures/taboos_repro-figure-1.png")
```

Here's the rub: We have no way of knowing from these analyses whether these patterns occur on an individual level. That is, we don't know whether for a given person, they are more reluctant to express their beliefs about statements they belief and less reluctant about statements they disbelieve. The group-level positive relationships could be composed of more heterogeneous individual-level relationships between belief and reluctance.

My first attempts to examine individual-level heterogeneity made use of linear mixed effects models that predicted reluctance to express one's beliefs about a statement with belief in that statement, with random intercepts and slopes for each participant and for each statement (total 4433 valid observations). In addition to a linear model, I also examined one with orthogonal linear and quadratic terms for belief. The detailed results for these models are available in the supplemental materials (https://github.com/RabbitSnore/taboos-revisited), and the results are easy to summarize. Both models suggested overall positive relationships between belief and reluctance (no surprise there), but the quadratic model suggested that the relationship was nonlinear, with a negative coefficient for the quadratic term. @fig-linear-quad displays linear and quadratic models of the relationship between belief and reluctance. Additionally and most notably, both models suggested massive variance in the random slopes for both participants and statements, suggesting considerable individual-level heterogeneity in the relationship between belief and reluctance. Additionally, the polynomial model provided a better fit to the data (BIC 40989.77 vs. 41267.35), suggesting there might indeed be nonlinear relationships at work here.

![Linear and quadratic model of reluctance as a function of belief in controversial statements](figures/taboos_linear-quad.png){#fig-linear-quad}

The fact that there is considerable individual variation is important, but we can take the analysis of different individual effects further. One option is to look for groups of people who have similar relationships between belief and reluctance. There are lots of ways to do this, but one of my favorites is a kind of latent class analysis in the framework of heterogeneous linear mixed effects models [see, e.g., @Proust-Lima_Philipps_Liquet_2017]. These kinds of models allow you to specify a regression model (often involving polynomial predictor terms, to account for nonlinearity) and some number of groups (latent classes). The estimation procedure finds parameters for each group, and each group can be characterized by different regression coefficients (in this case, different relationships between belief and reluctance). You fit a series of these models with varying numbers of classes, and then you see which number of classes fits the data best, usually according to fit statistics like the Bayesian Information Criterion (BIC). Then you've got your retained model, and you interpret that model. This procedure is what I did, testing up to six latent classes, with second-order (i.e., quadratic) orthogonal polynomials for the belief predictor and random intercepts for each statement. There are loads of limitations to this approach, but it will still provide useful information about potential differences in how individuals differ.

The best fitting model, according to the BIC, included three latent classes, visualized in @fig-class. The model identified *n* = 117 people in Class 1, *n* = 226 people in Class 2, and *n* = 125 people in Class 3.  This model suggests three general patterns: (1) people for whom belief and reluctance are only weakly related, (2) people who have a quadratic relationship between belief and reluctance, such that they are most reluctant to express their beliefs about topics they are uncertain about (recall that the midpoint of the scale is maximum uncertainty) but relatively unreluctant to express more confident beliefs (i.e., toward the poles of the scale), and (3) people for whom there is a positive relationship between belief and reluctance, with diminishing effects or slightly reversed effects at high levels of belief. We can immediately see the problem with describing the relationship between belief and reluctance with a single group-level model. The apparent positive relationship at the group-level is actually composed of a set of relationships, not all of which are positive (and possibly none of which are straightforwardly linear).

![Latent classes characterizing the relationship between reluctance and belief in controversial statements. Dashed lines represent mean belief across statements for each latent class.](figures/taboos_poly-predict-class.png){#fig-class}

Of course, it's another matter whether these three classes adequately characterize the idiographic effects. To make that assessment, we should look at each person's specific relationship between belief and reluctance, and we can fit a quadratic model for each of them. @fig-idio displays these relationships, with one participant per panel. Each plot has a color corresponding to the latent classes displayed in @fig-class. Even a casual look at @fig-idio makes it clear that the idiographic relationships between belief and reluctance are not captured by a single model. The latent class analysis does a better job capturing the many types of patterns that individuals exhibit, but it does seem to miss some notable patterns. For example, Class 2 seems to include many people who have diverse opinions across the statements and for whom belief and reluctance are largely unrelated. Additionally, Class 3 seems to include three different kinds of patterns: (1) those for whom there is a relatively straightforward positive relationship between belief and reluctance, (2) those for whom there is a positive relationship but who are less reluctant to express their opinions about statements they strongly endorse, and (3) those for whom there is a positive relationship, but because all their beliefs are below the midpoint of the scale, this relationship is explainable as a reduced willingness to express uncertain beliefs.

```{r}
#| label: fig-idio
#| fig-cap: Individual models of reluctance as a function of belief in controversial statements. Each panel represents a participant, and panels are ordered in ascending order of mean belief across the statements.
#| apa-twocolumn: true
#| out-width: "7in"

knitr::include_graphics("figures/taboos_idio-effects-poly.png")
```

It may be easier to see how well the latent class predictions line up with the individual-level relationships by directly overlaying them, as in @fig-idio-class. Inspecting this plot reinforces prior observations (which makes sense, given that it's just a different way of showing the same stuff). Here, we can see that Class 1 represents the individual patterns quite well. People in Class 1 are generally not reluctant to talk about any of their beliefs, but there some people will sometimes report high levels of reluctance for some statements, with little or no relationship to how much they believe the statement. Class 2 is noticeably messier. It seems that the latent class prediction does a reasonable job describing the overall group, but there is still considerable individual variation around the general pattern (which is also evident looking at @fig-idio). But if you focus your eye on the density of where the individual patterns lie on the plot, the cavity in the center bottom of the Class 2 plot makes it clear that people are indeed following the general pattern to a substantial extent. Much of the variation in patterns seems to come down to where on the belief scale individuals' reluctance increases and where it starts to decrease, and these differences seem to be what has produced the cute little cat ears of density that seem to protrude from the top of the curve. Finally, people in Class 3 seem to generally follow the pattern predicted by the latent class model to a high degree. Unlike Class 2, in which people's reluctance swings up and then back down, those in Class 3 swing upward and stay up as their belief increases, with a few individual exceptions.

```{r}
#| label: fig-idio-class
#| fig-cap: Latent class models and individual patterns of reluctance as a function of belief in controversial statements. Each panel represents a latent class, and points for each participant are joined with lines. Colored lines represent the average predicted relationship from the latent class mixed model.
#| apa-twocolumn: true
#| out-width: "7in"

knitr::include_graphics("figures/taboos_idio-class.png")
```

Take another look at @fig-fig-1. Now look at @fig-idio and @fig-idio-class again here. Same data, very different stories. I hope you can see why I am making such a fuss about individual-level relationships.

If you don't take into account individual variation in these data, group-level analyses overemphasize a pattern exhibited by a minority of participants. The relationships demonstrated by most members of Classes 1 and 2 (73.3% of participants) seem contrary to the general conclusions of @Clark_2024. The relationship demonstrated by many members of Class 3 are, however, consistent with the claimed positive relationship between controversial beliefs and reluctance. The group-level positive correlation between belief and reluctance observed by Clark et al seems to have been driven by the blending of Classes 2 and 3. If those separate patterns are not distinguished, part of Class 2's pattern (i.e., the lower half of the scale) would look consistent with a positive linear relationship. It is a classic case of group-level inferences not transferring to subgroups and to individuals. Additionally, rather than a positive relationship being widely characteristic of people, Class 3 represents a minority of people, though a sizable one. This distribution of the latent classes is consistent with the notion that some people subscribe to the narrative that free expression of controversial scientific ideas is under attack, but most people probably don't.

## People Differ in Concern About Reprisals, Based on More than Just Their Beliefs

@Clark_2024 asked participants to report the extent to which they felt they were at risk of nine potential consequences for voicing their beliefs about the controversial statements (0 = "No risk at all", 100 = "Very high risk"). If I'm right about Class 3 partly (but not purely) representing people who are recapitulating the political discourse about "taboo" scientific ideas being under attack by censorious forces, then they should be the ones who are most concerned about reprisals for expressing their beliefs. Indeed, that is what we see in @fig-risk. 

```{r}
#| label: fig-risk
#| fig-cap: Differences Across Latent Classes in Perceived Risk
#| apa-twocolumn: true
#| out-width: "7in"

knitr::include_graphics("figures/taboos_class_risk.png")
```

There are some immediately striking differences across the classes. Two that catch my eye are the massive divergences in the perceived risk of student boycotts (Class 1 *M* = 20.2, *SD* = 25.7; Class 2 *M* = 40.5, *SD* = 31.6; Class 3 *M* = 61.9, *SD* = 31.6) and disciplinary action (Class 1 *M* = 13.2, *SD* = 23.6; Class 2 *M* = 31.5, *SD* = 29.8; Class 3 *M* = 51.5, *SD* = 31.7). Why is Class 3 so concerned about these potential risks, while those in Class 1 are largely unconcerned? These groups of people seem to be on different planets in terms of their risk assessments. Perhaps people in Class 3 have the sense that the only thing holding back a flood of students with picket signs and unjustified university investigations is professors keeping their beliefs suppressed -- but on what basis do they think that? Again, context is key here. Student boycotts and disciplinary actions are simply not very common reactions to professors making claims in teaching or research contexts. There are more people in this sample than there are professors who have been subject to those kinds of consequences in the last eight years^[Yeah, I know that doesn't really make sense as a comparison. The point is that the number is small.].

Of course, these differences in perceived risk are confounded with the differences in belief in the statements across each of the latent classes (Class 1 *M* = 41.8, *SD* = 31.8; Class 2 *M* = 47.0, *SD* = 31.0; Class 3 *M* = 54.3, *SD* = 32.2). But we can partial out those effects, to examine the extent to which these differences in perceived risk persist in spite of the differences in belief. If people in Class 3 are concerned about reprisals at least partly because they have been influenced by the political narrative, whereas the other latent classes are less influenced or not influenced by this narrative, then these differences in perceived risk should persist even when controlling for their level of belief in the statements.

To partial out the influence of belief, I fit a regression model for each of the nine perceived risks, predicting each risk rating with orthogonal linear and quadratic terms for belief in each of the ten statements (20 regressors for each model)^[Another more conventional way to approach this same question would be to simply add the predicted latent classes as regressors. I prefer the residuals-focused approach because it lends itself nicely to visualization. But I did it the more conventional way as well (because I know you freaks love a significance test), and all nine models indicated that all three classes were significantly different from each other such that Class 1 is the lowest, Class 2 was in the middle, and Class 3 was the highest.The one exception was the model for threats of physical violence, which suggested that Class 2 and Class 3 were not significantly different from each other. The only other consistently significant predictor was the belief that conservatives are discriminated against in the social sciences.]. Overall, these models performed very well, by the standards of social science, highest $R^2$ = .40, lowest $R^2$ = .13. Across all perceived risks, the strongest predictor in each regression model was belief that the social sciences in the US are biased against conservatives -- indeed, to the exclusion of most of the other beliefs. The more one believed conservatives are targets of discrimination, the more one believed one is at risk of each of the nine consequences. In seven out of nine of the models, the second strongest predictor was the belief that Black people are targets of discrimination in the academy. The less one believed that Black people are discriminated against, the more one generally believed one is at risk. The details of these models are available in the supplemental materials (https://github.com/RabbitSnore/taboos-revisited).

From each model, I extracted the residuals, which can be interpreted as the remaining part of people's perceived risk, not accounted for by their beliefs. The differences in these residuals across the three estimated latent classes are displayed in @fig-residual. As can be easily seen, the differences are mitigated compared to the raw ratings, but there is a consistent pattern across all perceived risks, such that Class 1 is the least concerned, followed by Class 2, and Class 3 is the most concerned about each of these possible risks of voicing their beliefs. Given that these residuals have, to the best of the ability of the regression models, removed the influence of people's beliefs, it seems clear that it is not merely the substance of their beliefs that is driving people's concern (or lack of concern) about these potential consequences.

```{r}
#| label: fig-residual
#| fig-cap: Differences Across Latent Classes in Perceived Risk Residuals, with the Effects of Belief Removed
#| apa-twocolumn: true
#| out-width: "7in"

knitr::include_graphics("figures/taboos_class_risk_residuals.png")
```

The folks predicted to be in Class 1 espouse a wide range of beliefs, are generally not reluctant to share any of them, and are relatively unconcerned with potential reprisals for sharing their beliefs. Those in Class 2 are characterized by a general pattern of being more reluctant to speak about controversial topics about which they are uncertain, and they are more concerned about potential consequences of expressing their beliefs compared to Class 1 but less concerned than Class 3. I can't say for certain what is happening in the hearts and minds of these people, but one possible explanation is that they are aware that these statements are controversial and politically charged, and they are worried that voicing an uninformed or wishy-washy opinion might come with negative consequences. The people predicted to be in Class 3, who are characterized by a positive relationship between belief and reluctance, were the most concerned about the risks of expressing their beliefs (again, even when accounting for what they believe). 

What can we conclude from these analyses? At minimum, it is clear that people have different assessments of their risk of facing these potential consequences that flow from sources beyond their belief in the controversial statements, and people's differences in perceived risks correspond to the relationship they show between belief and reluctance (i.e., the latent classes). That is, it doesn't just matter *what* you believe. It matters, on an individual level, what relationship your beliefs have to your willingness to express them. These differences in perceived risks, as well as the finding that the specific belief that conservatives are discriminated against is the strongest predictor of perceived risk, are not fully dispositive, but these results are consistent with the notion that the extent to which people subscribe to conservative political narratives could be driving these patterns of results. 

# What Does This Mean?

In my view, there are at least two related types of problems with the conclusions of Clark et al: There are issues primarily related to framing and labeling, and there are misinterpretations of the data. As I discussed earlier, applying the label "self-censorship" to the reluctance variable is problematic given the item text, but it is also problematic given the clear pattern that many people report being more reluctant to express opinions about controversial topics about which they are uncertain (i.e., near the midpoint of the scale). Recall that this sample of professors were not necessarily experts on the research on any of the topics they were asked about. Thus, this kind of reluctance is self-censorship perhaps only insofar as it is self-censorious to try to avoid sharing opinions about controversial topics you aren't familiar with.

And then there are the issues with the interpretation of the data. For example, @Clark_2024 write

> Scholars with more socially desirable beliefs were less likely to self-censor, less fearful of punishments, and less likely to perceive the existence of taboos. These patterns may explain why scholars sometimes quarrel about whether academic freedom is at risk—scholars are likelier to notice boundaries when they have crossed them (in their own minds, if not publicly). These patterns of self-censorship also suggest that professional discourse surrounding taboo topics (e.g., at conferences, in faculty meetings, on social media) may be systematically biased toward rejecting taboo conclusions because those who hold taboo empirical beliefs are more likely to remain silent than others. (p.14)

In addition to the conceptual issues (e.g., the use of the term “empirical beliefs”), given what we’ve seen in the individual level data, this set of conclusions doesn’t really hold up. 

The data do support the conclusion that some people are more reluctant to voice belief in these ten statements. But an awful lot of them expressed no such reluctance at any level of belief. This general lack of reluctance characterized those predicted to be in Class 1, and though we should be wary of reifying the latent class analysis, it's worth noting that there were almost as many people in Class 1 (*n* = 117) as there were in Class 3 (*n* = 125).

Do these patterns suggest that professional discourse is “biased toward rejecting taboo conclusions”? I don't think so. If these ideas were taboos, we should see minimal density in the bottom right corner of across all panels of @fig-idio-class, perhaps only populated by a few brave souls. But that's not what we see. Instead, we only see such a lack of density in one of the three panels (Class 3). The data suggest that, rather than “taboo” beliefs being self-censored out of the discourse, some people indeed report being reluctant to voice their endorsement of controversial ideas, but a sizable proportion of professors in the US seem to be totally fine expressing their controversial beliefs, as long as they are confident about them. It is a minority of people who are reluctant -- and we still don't know if these people are actually remaining silent. Again, people regularly do things reluctantly. We are not dealing with a "silent majority." We are dealing with a "reluctant minority."

Moreover, if we trust the latent class analysis, there is a roughly equally sized minority of people who are not reluctant to voice most of their beliefs and whose beliefs run the gamut from full rejection to full endorsement of the controversial statements. So why does the reluctant minority exist, amid this wider atmosphere where belief and reluctance are less correlated or uncorrelated? Who's afraid of the big bad woke? Obviously, I don't know for sure. Unfortunately, the data from @Clark_2024 cannot provide a clear answer as to what underpins scholars' perceptions of the risks of expressing their views. Neither their survey nor their pilot interview study asked participants to explain their basis for any concerns they have or to provide examples of experiences that have shaped their views. As I see it, what demands an explanation is the individual-level variation in the relationship between belief and reluctance and the differences in the assessment of risks of consequences for expression. In the absence of more direct evidence, my best guess is what I suggested before, that many scholars are recapitulating a political narrative that academic freedom is under attack -- particularly the freedom to express belief in statements like the ones examined by @Clark_2024. This narrative may not have found widespread purchase among psychology professors in the US, but among those for whom it has, it may have profoundly influenced their assessments of the risks of expressing their beliefs.

# Conclusion

The present analyses make it clear that the the conclusions of @Clark_2024 concerning the relationship between belief in controversial ideas and reluctance to express those ideas are, at best, very incomplete and, at worst, misleading.

I want to return to what I prompted you, reader, to think about earlier: Why is @Clark_2024 written the way that it is? I'm quite sure that this paper has been revised to address peer reviewer criticisms, but the words on the page remain the authors' choices. And it is worth considering what underlies some of those choices. Why have they used the term "self-censorship" to refer to a variable I think is more appropriately called reluctance? Why have they used the term "taboo" to refer to ideas that a lot of people seem to believe in and frequently seem willing to talk about? Why have they used the term "empirical belief" to describe their participants' responses, when the sample consists of people who are not necessarily experts on any of these topics and when they were asked to report what they believed, rather than how they assessed extant research? Viewed in the totality of the context in which they occur, what are the implications and consequences of these rhetorical choices? "Scholars' self-censorship of taboo empirical beliefs" certainly sounds like a serious social and professional problem. It sounds like important truths might be being suppressed by censorious forces. This framing and labeling suggests the presence of peril to a much greater extent, compared to saying that some scholars are sometimes reluctant to express their opinions about controversial topics that they might not actually know much about anyway. I certainly don't begrudge authors for persuasive rhetorical flourishes, but there's surely a boundary past which persuasiveness becomes mischaracterization. I trust you, reader, to evaluate for yourself whether that line has been crossed here. For my part, I believe it has.

Clark et al write, "Disagreements and debates can be productive in science, particularly when participants are equipped and required to make their case with data" (p.16). In many ways, I must agree. I, too, subscribe to the Mertonian norm of universalism that compels us to restrain our personal biases with criteria for evaluation that exist not exclusively in our own heads but are shared across a scholarly community. I would be lying if I said I approached this reanalysis from an unbiased perspective, and throughout the process, in my weaker moments when I'd prefer to just scoff and roll my eyes, I have found it useful -- indeed, vital -- to remind myself that my criticisms must be constructed rigorously, bearing in mind an imagined audience of the skeptical and unsympathetic. Even primarily quantitative researchers benefit from reflexivity. Accordingly, I'm grateful that @Clark_2024 made their data openly accessible so that I could make this case empirically, not just theoretically. And I find myself in agreement with another of their conclusions: Sometimes it is useful to have someone adversarial to your ideas looking over your shoulder. 

# References
